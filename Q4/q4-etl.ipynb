{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559878a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_json_data(file_path):\n",
    "    \"\"\"Read JSON (array or ndjson) and flatten nested 'readings' arrays.\n",
    "    Returns DataFrame with one row per reading and columns:\n",
    "    sensor_id, truck_id, timestamp, temperature (C), humidity, ...other fields\n",
    "    \"\"\"\n",
    "    p = Path(file_path)\n",
    "    if not p.exists():\n",
    "        print(\"File tidak ditemukan:\", file_path)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # load JSON: support array or ndjson (one JSON object per line)\n",
    "    text = p.read_text(encoding='utf-8').strip()\n",
    "    if not text:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    records = []\n",
    "    try:\n",
    "        if text.startswith('['):\n",
    "            data = json.loads(text)\n",
    "            records = data if isinstance(data, list) else [data]\n",
    "        else:\n",
    "            # ndjson or single object\n",
    "            lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "            if len(lines) == 1:\n",
    "                obj = json.loads(lines[0])\n",
    "                records = obj if isinstance(obj, list) else [obj]\n",
    "            else:\n",
    "                for line in lines:\n",
    "                    try:\n",
    "                        records.append(json.loads(line))\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"JSON decode error\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for item in records:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "        base = {}\n",
    "        # extract top-level identifiers if present\n",
    "        base['sensor_id'] = item.get('sensor_id') or item.get('id') or None\n",
    "        base['truck_id'] = item.get('truck_id') or item.get('truck') or None\n",
    "\n",
    "        readings = item.get('readings')\n",
    "        # if readings is a list -> one row per element\n",
    "        if isinstance(readings, list):\n",
    "            for r in readings:\n",
    "                if not isinstance(r, dict):\n",
    "                    rows.append({**base, 'reading': r})\n",
    "                    continue\n",
    "                row = dict(base)\n",
    "                # timestamp preference: reading timestamp overrides item-level timestamp\n",
    "                ts = r.get('timestamp') or r.get('time') or item.get('timestamp') or item.get('time')\n",
    "                row['timestamp'] = ts\n",
    "                # normalize possible temperature keys\n",
    "                if 'temp' in r:\n",
    "                    row['temperature'] = r.get('temp')\n",
    "                elif 'temperature' in r:\n",
    "                    row['temperature'] = r.get('temperature')\n",
    "                if 'humidity' in r:\n",
    "                    row['humidity'] = r.get('humidity')\n",
    "                row.update({k:v for k,v in r.items() if k not in ('timestamp','time','temp','temperature','humidity')})\n",
    "                rows.append(row)\n",
    "        # if readings is dict -> merge\n",
    "        elif isinstance(readings, dict):\n",
    "            row = dict(base)\n",
    "            ts = readings.get('timestamp') or readings.get('time') or item.get('timestamp') or item.get('time')\n",
    "            row['timestamp'] = ts\n",
    "            if 'temp' in readings:\n",
    "                row['temperature'] = readings.get('temp')\n",
    "            elif 'temperature' in readings:\n",
    "                row['temperature'] = readings.get('temperature')\n",
    "            if 'humidity' in readings:\n",
    "                row['humidity'] = readings.get('humidity')\n",
    "            row.update({k:v for k,v in readings.items() if k not in ('timestamp','time','temp','temperature','humidity')})\n",
    "            rows.append(row)\n",
    "        else:\n",
    "            # no readings field -> treat item as single reading\n",
    "            row = dict(base)\n",
    "            ts = item.get('timestamp') or item.get('time')\n",
    "            row['timestamp'] = ts\n",
    "            if 'temp' in item:\n",
    "                row['temperature'] = item.get('temp')\n",
    "            elif 'temperature' in item:\n",
    "                row['temperature'] = item.get('temperature')\n",
    "            if 'humidity' in item:\n",
    "                row['humidity'] = item.get('humidity')\n",
    "            # include other top-level fields\n",
    "            row.update({k:v for k,v in item.items() if k not in ('sensor_id','truck_id','readings','timestamp','time','temp','temperature','humidity')})\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # normalize timestamp column\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    print(f\"Extracted {len(df)} rows from {file_path}\")\n",
    "    return df\n",
    "\n",
    "def transform_data(df):\n",
    "    \"\"\"Transform DataFrame:\n",
    "    - interpret 'temperature' as Celsius\n",
    "    - add temperature_f (F) and comfort_index = temp_c / humidity * 100 when possible\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(\"No data to transform\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # ensure numeric temperature and humidity\n",
    "    if 'temperature' in df.columns:\n",
    "        df['temperature_c'] = pd.to_numeric(df['temperature'], errors='coerce')\n",
    "    else:\n",
    "        df['temperature_c'] = pd.NA\n",
    "\n",
    "    if 'humidity' in df.columns:\n",
    "        df['humidity'] = pd.to_numeric(df['humidity'], errors='coerce')\n",
    "    else:\n",
    "        df['humidity'] = pd.NA\n",
    "\n",
    "    # convert to Fahrenheit\n",
    "    df['temperature_f'] = df['temperature_c'].apply(lambda c: round((c * 9/5) + 32, 2) if pd.notna(c) else pd.NA)\n",
    "\n",
    "    # comfort index: temp_c / humidity * 100 (guard divide by zero)\n",
    "    def compute_comfort(row):\n",
    "        t = row.get('temperature_c')\n",
    "        h = row.get('humidity')\n",
    "        try:\n",
    "            if pd.isna(t) or pd.isna(h) or h == 0:\n",
    "                return pd.NA\n",
    "            return round((t / h) * 100, 2)\n",
    "        except Exception:\n",
    "            return pd.NA\n",
    "\n",
    "    df['comfort_index'] = df.apply(compute_comfort, axis=1)\n",
    "\n",
    "    print(f\"Transformed: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    return df\n",
    "\n",
    "def load_to_csv(df, output_path):\n",
    "    \"\"\"Save DataFrame to CSV\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(\"No data to save\")\n",
    "        return\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Saved CSV: {output_path} ({df.shape[0]} rows)\")\n",
    "    except Exception as e:\n",
    "        print(\"Error saving CSV:\", e)\n",
    "\n",
    "# Execute ETL pipeline\n",
    "raw_data = extract_json_data('sensors.json')\n",
    "transformed_data = transform_data(raw_data)\n",
    "load_to_csv(transformed_data, 'etl_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a0513",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Execute ETL pipeline\n",
    "raw_data = extract_json_data('uts-pid-2025/PID/datasets/sensors_2024-10-13.json')\n",
    "transformed_data = transform_data(raw_data)\n",
    "load_to_csv(transformed_data, 'etl_output.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
